{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmake (from -r requirements.txt (line 1))Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading cmake-3.29.2-py3-none-win_amd64.whl (36.2 MB)\n",
      "     ---------------------------------------- 36.2/36.2 MB 5.6 MB/s eta 0:00:00\n",
      "Collecting gdown (from -r requirements.txt (line 2))\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (6.15.2)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (7.6.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: jsonargparse in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (4.27.7)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (4.19.2)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (4.0.8)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (3.8.1)\n",
      "Requirement already satisfied: numba>=0.50 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (0.55.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (1.21.5)\n",
      "Collecting opencv-python-headless (from -r requirements.txt (line 12))\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-win_amd64.whl (38.5 MB)\n",
      "     ---------------------------------------- 38.5/38.5 MB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (1.4.4)\n",
      "Requirement already satisfied: progress in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 14)) (1.6)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 15)) (1.0.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 16)) (0.11.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 17)) (0.15.2)\n",
      "Requirement already satisfied: umap-learn>=0.4.5 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 18)) (0.5.6)\n",
      "Requirement already satisfied: yapf in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 19)) (0.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from gdown->-r requirements.txt (line 2)) (4.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from gdown->-r requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from gdown->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from gdown->-r requirements.txt (line 2)) (4.64.1)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (7.31.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (8.6.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (1.5.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (21.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipykernel->-r requirements.txt (line 3)) (5.13.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 4)) (5.5.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 4)) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: PyYAML>=3.13 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jsonargparse->-r requirements.txt (line 6)) (6.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jsonschema->-r requirements.txt (line 7)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jsonschema->-r requirements.txt (line 7)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jsonschema->-r requirements.txt (line 7)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jsonschema->-r requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab->-r requirements.txt (line 8)) (2.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab->-r requirements.txt (line 8)) (4.11.3)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab->-r requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab->-r requirements.txt (line 8)) (5.5.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab->-r requirements.txt (line 8)) (2.10.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab->-r requirements.txt (line 8)) (2.25.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab->-r requirements.txt (line 8)) (0.2.3)\n",
      "Requirement already satisfied: tomli in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab->-r requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 9)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 9)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 9)) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 9)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 9)) (6.1.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from numba>=0.50->-r requirements.txt (line 10)) (0.38.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from numba>=0.50->-r requirements.txt (line 10)) (63.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 13)) (2022.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2.post1->-r requirements.txt (line 15)) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2.post1->-r requirements.txt (line 15)) (2.2.0)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from torchvision->-r requirements.txt (line 17)) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision->-r requirements.txt (line 17)) (4.3.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision->-r requirements.txt (line 17)) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision->-r requirements.txt (line 17)) (2.8.4)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from umap-learn>=0.4.5->-r requirements.txt (line 18)) (0.5.12)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.3->jupyterlab->-r requirements.txt (line 8)) (3.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.18.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (3.0.20)\n",
      "Requirement already satisfied: pygments in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (2.11.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab->-r requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterlab->-r requirements.txt (line 8)) (2.5.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterlab->-r requirements.txt (line 8)) (302)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (6.4.4)\n",
      "Requirement already satisfied: overrides in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.14.1)\n",
      "Requirement already satisfied: pywinpty in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (2.0.12)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.13.1)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.58.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r requirements.txt (line 8)) (2.13.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r requirements.txt (line 8)) (0.9.6)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->-r requirements.txt (line 4)) (2.16.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from requests[socks]->gdown->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from requests[socks]->gdown->-r requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from requests[socks]->gdown->-r requirements.txt (line 2)) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from requests[socks]->gdown->-r requirements.txt (line 2)) (2023.5.7)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 4)) (7.0.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown->-r requirements.txt (line 2)) (2.3.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from requests[socks]->gdown->-r requirements.txt (line 2)) (1.7.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.8.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: testpath in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.5.13)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 3)) (0.2.5)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (21.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.1->torchvision->-r requirements.txt (line 17)) (1.2.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jsonschema->-r requirements.txt (line 7)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jsonschema->-r requirements.txt (line 7)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jsonschema->-r requirements.txt (line 7)) (2.4)\n",
      "Requirement already satisfied: uri-template in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jsonschema->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from jsonschema->-r requirements.txt (line 7)) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (1.15.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 8)) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages (from isoduration->jsonschema->-r requirements.txt (line 7)) (1.2.2)\n",
      "Installing collected packages: opencv-python-headless, cmake, gdown\n",
      "Successfully installed cmake-3.29.2 gdown-5.1.0 opencv-python-headless-4.9.0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\abdul rasool\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Tutorial for GEORGE\n",
    "\n",
    "In this notebook, we demonstrate a simple experiment comparing empirical risk minimization (ERM) and our method (GEORGE) on the MNIST dataset, using a small three-layer CNN model. In this simple example, GEORGE improves worst-case accuracy (i.e., the minimum accuracy over any subclass) compared to ERM. More sophisticated experiments are described in the blog post (and paper, coming soon). The notebook can be run with or without GPU support. For a script version rather than a notebook, see `stratification/run.py`.\n",
    "\n",
    "There are four main sections to this notebook:\n",
    "1. **Setup**: Imports and setting up the dataset and model.\n",
    "2. **Train ERM Model**: we train an empirical risk minimization (ERM) model on the `superclass` labels.\n",
    "3. **Cluster Activations**: using the feature representation of the ERM model, we leverage dimensionality reduction and clustering techniques in order to estimate approximate `subclass` labels for each example.\n",
    "4. **Train \"GEORGE\" Model**: we train a new model that exploits the recovered `subclass` labels to improve worst-case performance on them, using group distributionally robust optimization (GDRO) \\[[Sagawa et al. (2020)](https://arxiv.org/abs/1911.08731)\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "### 1.1 Imports and configuration setup\n",
    "Before you start, make sure you have set up the repository correctly and installed all dependencies, as described in the README.\n",
    "\n",
    "All training options are handled by a single `config` object. In this tutorial, we use the configuration provided in `demo_config.json`. To see how configuration files are defined, validated, and optionally modified via the command line, check out `stratification/utils/parse_args.py` and `stratification/utils/schema.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23512\\811388772.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstratification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mharness\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGEORGEHarness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstratification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_cuda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstratification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Ed 1\\BTP\\hidden-stratification-master\\hidden-stratification-master\\stratification\\harness.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstratification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstratification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstratification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstratification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeorge_classification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGEORGEClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Ed 1\\BTP\\hidden-stratification-master\\hidden-stratification-master\\stratification\\cluster\\models\\reduction.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#from umap import UMAP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mumap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mumap_\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mUMAP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\umap\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mparametric_umap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParametricUMAP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     warn(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\umap\\parametric_umap.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Used for tf.data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     warn(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    417\u001b[0m \"\"\"\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_service_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# ==============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwrapt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \"\"\"\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sparse_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdoc_controls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0m_np_bfloat16\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_bfloat16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_bfloat16_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0m_np_float8_e4m3fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_float8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_float8_e4m3fn_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0m_np_float8_e5m2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_float8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_float8_e5m2_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from stratification.harness import GEORGEHarness\n",
    "from stratification.utils.utils import set_seed, init_cuda\n",
    "from stratification.utils.parse_args import get_config\n",
    "from stratification.cluster.models.cluster import GaussianMixture\n",
    "from stratification.cluster.models.reduction import UMAPReducer\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "\n",
    "# repository base directory\n",
    "os.chdir(\"../\")\n",
    "REPO_DIR = os.getcwd()\n",
    "print(REPO_DIR)\n",
    "with open('configs/demo_config.json', 'r') as f:\n",
    "    config = json.dumps(json.load(f))\n",
    "config = get_config([config])\n",
    "\n",
    "os.chdir(os.path.join(REPO_DIR, 'stratification'))\n",
    "\n",
    "use_cuda_if_available = False  # change to True if you want to use CUDA\n",
    "use_cuda = use_cuda_if_available and torch.cuda.is_available()\n",
    "# set seeds for reproducibility\n",
    "set_seed(config['seed'], use_cuda)\n",
    "# initialize CUDA, if available\n",
    "init_cuda(config['deterministic'], config['allow_multigpu']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Initialize GEORGEHarness\n",
    "\n",
    "The `GEORGEHarness` is an object that handles the \"bookkeeping\" for each of the steps outlined in this tutorial, such as setting up experiment directories and loading/saving models.  Experiment files are stored in the base directory specified by `config['exp_dir']`. Each experiment run is stored in a subdirectory of this base directory whose filename is based on the (1) training method (ERM, GEORGE, etc.), (2) the timestamp, and (3) a random hash (to avoid collisions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harness = GEORGEHarness(config, use_cuda=use_cuda, log_format='simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Get Data and Model Architecture\n",
    "\n",
    "In this tutorial, we'll use the MNIST dataset. In our case, the task will be to classify digits as < 5 or  5; these correspond to the two *superclasses*. The *subclasses* are the individual digits (0,1,2,3,4 are the subclasses of the first superclass, and 5,6,7,8,9 are the subclasses of the second superclass).\n",
    "\n",
    "When fetching the dataloaders and NN architecture, we can also specify the \"mode\" (training method), as one can specify different data and model options in the configuration for the different training methods.\n",
    "\n",
    "Additional datasets and architectures can be added under `stratification/classification/datasets` and `stratification/classification/models`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = harness.get_dataloaders(config, mode='erm')\n",
    "num_classes = dataloaders['train'].dataset.get_num_classes('superclass')\n",
    "model = harness.get_nn_model(config, num_classes=num_classes, mode='erm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train ERM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already initialized our model, a simple CNN architecture. Let's print it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model architecture:')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to train a classifier! First we'll just train a standard classifier using empirical risk minimization (a fancy term for minimizing the average training loss). We'll print out both the overall accuracy and the true robust accuracy (i.e., the minimum accuracy on any subclass), along with the losses as well. The robust accuracy is the metric we are interested in maximizing. We train our models as though we don't know the subclass (digit) labels, in which case we can't actually measure the true robust accuracy. In reality, we do know the subclass labels for this dataset, so we'll measure per-subclass performance to see how well each method *really* does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erm_dir = harness.classify(config['classification_config'],  model, dataloaders, 'erm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall test accuracy is around **92%**, but the robust accuracy is quite a bit lower at around **82%**. (Note: Results may vary based on random seed, platform, GPU use, etc.) Let's see if we can improve on this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cluster Model Activations\n",
    "\n",
    "Now, we'll cluster the data of each superclass, to try and automatically identify the subclasses. However, just clustering the raw data usually doesn't work that well - instead, we cluster in the *feature space* of a trained model. We just trained an ERM model on the task, so we'll now use this model to extract features which we use for clustering. Specifically, the features are the activations (outputs) of the penultimate layer (right before the classification layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Initialize Cluster Model and Reduction Model\n",
    "\n",
    "The clustering procedure consists of two steps:\n",
    "1. Dimensionality reduction of the activations (optional). If `reduction_model` is `None`, the raw activations are used.\n",
    "2. Fitting a separate cluster model on the reduced training activations of each superclass.\n",
    "\n",
    "We'll use UMAP for dimensionality reduction, and we'll use Gaussian mixture model clustering. For simplicity, in this tutorial we fix the number of clusters per superclass to 5 (the true number of subclasses per superclass for this task). *Automatic* selection of the number of clusters based on unsupervised metrics (such as the Silhouette score) is also supported - in fact, our experiments in the blog post and paper are run using this automatic selection procedure, rather than pre-specifying the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction model\n",
    "reduction_model = UMAPReducer(random_state=12345, n_components=2)\n",
    "# Clustering model\n",
    "cluster_model = GaussianMixture(covariance_type=\"full\", n_components=5, n_init=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Run `harness.reduce`\n",
    "\n",
    "Now, we use UMAP to dimensionality-reduce the activations to produce the \"features\" that we'll cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_dir = harness.reduce(config['reduction_config'], reduction_model,\n",
    "                               inputs_path=os.path.join(erm_dir, 'outputs.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Run `harness.cluster`\n",
    "\n",
    "Now, we cluster the aforementioned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we cluster the features separately for each superclass.\n",
    "# This step also generates and saves visualizations of the data, which we'll look at in the next part.\n",
    "cluster_dir = harness.cluster(config['cluster_config'], cluster_model,\n",
    "                              inputs_path=os.path.join(reduction_dir, 'outputs.pt'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Visualizing the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the clusters that we found. Since we apply UMAP to reduce to dimension 2, we can directly visualize the data in this two-dimensional \"feature space\" - see below! The first row corresponds to the first superclass (< 5, i.e. digits 0-4) and the second row corresponds to the second superclass ( 5, i.e. digits 5-9). On the left, we color each point by its assigned cluster label. On the right, we color each point by its actual subclass (i.e., which digit that datapoint is). As we can see, the individual subclasses are fairly easy to distinguish in feature space, and as a result *up to permutation* the clusters we find match up quite well with the actual subclasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_dir = os.path.join(cluster_dir, 'visualizations')\n",
    "fig, axarr = plt.subplots(2, 2, figsize=(18, 12), gridspec_kw={'wspace':0, 'hspace':0}, squeeze=True, dpi=300)\n",
    "for i in range(2):\n",
    "    axarr[i, 0].imshow(mpimg.imread(os.path.join(viz_dir, f'train/group_{i}_cluster_viz.png')))\n",
    "    axarr[i, 0].axis('off')\n",
    "    axarr[i, 1].imshow(mpimg.imread(os.path.join(viz_dir, f'train/group_{i}_true_subclass_viz.png')))\n",
    "    axarr[i, 1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Final (GEORGE) Model\n",
    "\n",
    "Training the GEORGE model is simple. The only new thing to pass in is the `clusters.pt` path. This is a pickled dictionary saved by `harness.cluster` that contains the cluster labels assigned to the datapoints. These estimated cluster labels are used as a surrogate for the subclass labels. We now train a model to minimize the *worst-case* loss over the clusters using GDRO. Since the cluster assignments are similar to the true subclass labels up to permutation, we expect that this procedure should also improve worst-case accuracy on the true subclasses.\n",
    "\n",
    "As before, we'll print out both the overall accuracy and true robust accuracy. We'll also print out the *estimated* robust accuracy, which is the minimum accuracy on any *cluster*. Unlike the true robust accuracy, this is something we can actually measure even when we don't know the true subclass labels. If the cluster labels are a good estimate of the true subclass labels, then this estimated robust accuracy should be a good estimate of the true robust accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(config['seed'], use_cuda)  # reset random state\n",
    "# Specify path to estimated subclass labels\n",
    "dataloaders = harness.get_dataloaders(\n",
    "    config, mode='george', subclass_labels=os.path.join(cluster_dir, 'clusters.pt'))\n",
    "# Initialize new model\n",
    "model = harness.get_nn_model(config, num_classes=num_classes, mode='george')\n",
    "\n",
    "# Train the final (GEORGE) model\n",
    "george_dir = harness.classify(config['classification_config'], model, dataloaders,\n",
    "                              mode='george')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [2,3]\n",
    "list(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy is similar to that of the ERM model, but the robust accuracy has improved to around **89%**!\n",
    "In addition, our estimate of the robust accuracy (**91%**) is quite close to the actual robust accuracy (and these two metrics remain close throughout the entire training run).\n",
    "Again, results may vary somewhat - but on average across random seeds, the GEORGE model outperforms the ERM model in terms of robust accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates our framework (GEORGE) for estimating subclasses and improving worst-case subclass accuracy, on a simple \"toy\" example. Although the end-to-end performance gains are modest in this case, on more complex datasets the gains can be quite dramatic! See our blog post and paper for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
